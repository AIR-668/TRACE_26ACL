{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9793e5b2-d258-4095-8476-f506ecccf5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspace\n",
      "Files here:\n",
      "['.git', '.gitignore', 'README.md', 'aristotle.png', 'data', 'evaluate.py', 'negate.py', 'prompts', 'requirements.txt', 'search_resolve.py', 'translate_decompose.py', 'utils.py', 'experiments', 'notebooks', 'apptainer', 'scripts', 'TRACE.md', '__pycache__', 'results', 'logs', 'wandb', 'test_env']\n",
      "\n",
      "LogicNLI data dir:\n",
      "['dev.json']\n"
     ]
    }
   ],
   "source": [
    "# Cell 1：切到项目根目录 + 基础检查\n",
    "import os\n",
    "\n",
    "## 切换工作目录到 Aristotle/TRACE 项目根\n",
    "os.chdir(\"/workspace\")\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "print(\"Files here:\")\n",
    "print(os.listdir(\".\"))\n",
    "print(\"\\nLogicNLI data dir:\")\n",
    "print(os.listdir(\"data/LogicNLI\"))\n",
    "\n",
    "## 方案 1：告诉 wandb 这是脚本，而不是 notebook（最推荐）\n",
    "## 在你的 notebook 开头加入：\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"baseline_ Aristotle_LogicNLI_v2.ipynb\"\n",
    "os.environ[\"WANDB_DISABLE_NOTEBOOK\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37639699-8260-4fe5-a057-ac4b02d55692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OpenAI API key:  ········\n",
      "wandb API key (留空则跳过 login):  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2：安全设置 OpenAI & wandb（不要提交到 Git）\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "# 建议用 getpass，避免 key 明文出现在界面 / 历史中\n",
    "openai_key = getpass.getpass(\"OpenAI API key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
    "\n",
    "# 如果需要手动登录 wandb（通常一次登录之后 cookie 会保存）\n",
    "import wandb\n",
    "\n",
    "wandb_api = getpass.getpass(\"wandb API key (留空则跳过 login): \")\n",
    "if wandb_api.strip():\n",
    "    os.environ[\"WANDB_API_KEY\"] = wandb_api\n",
    "    wandb.login(key=wandb_api)\n",
    "else:\n",
    "    print(\"跳过 wandb.login（用已有登录状态）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e561089-4995-47cb-a7d0-f6004c4c9218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LogicNLI-dev-gpt-4o-1764737629</strong> at: <a href='https://wandb.ai/chengjiezheng-umb/TRACE_LogicNLI/runs/d48c29al' target=\"_blank\">https://wandb.ai/chengjiezheng-umb/TRACE_LogicNLI/runs/d48c29al</a><br> View project at: <a href='https://wandb.ai/chengjiezheng-umb/TRACE_LogicNLI' target=\"_blank\">https://wandb.ai/chengjiezheng-umb/TRACE_LogicNLI</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./notebooks/wandb/run-20251203_045349-d48c29al/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/notebooks/wandb/run-20251203_045639-ig7dj2sh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/chengjiezheng-umb/TRACE_LogicNLI/runs/ig7dj2sh' target=\"_blank\">LogicNLI-dev-gpt-4o-1764737799</a></strong> to <a href='https://wandb.ai/chengjiezheng-umb/TRACE_LogicNLI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/chengjiezheng-umb/TRACE_LogicNLI' target=\"_blank\">https://wandb.ai/chengjiezheng-umb/TRACE_LogicNLI</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/chengjiezheng-umb/TRACE_LogicNLI/runs/ig7dj2sh' target=\"_blank\">https://wandb.ai/chengjiezheng-umb/TRACE_LogicNLI/runs/ig7dj2sh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb run url: https://wandb.ai/chengjiezheng-umb/TRACE_LogicNLI/runs/ig7dj2sh\n",
      "Log will be saved to: experiments/logs/LogicNLI_dev_gpt-4o_20251203_045641.txt\n"
     ]
    }
   ],
   "source": [
    "# Cell 3：实验配置 & 初始化 wandb run\n",
    "import time\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# 基本配置\n",
    "PROJECT_DIR = \"/workspace\"\n",
    "DATASET_NAME = \"LogicNLI\"\n",
    "SPLIT = \"dev\"\n",
    "MODEL_NAME = \"gpt-4o\"      # 你也可以换成 gpt-4.1 等\n",
    "MAX_NEW_TOKENS = 2048\n",
    "BATCH_NUM = 1\n",
    "\n",
    "RUN_NAME = f\"{DATASET_NAME}-{SPLIT}-{MODEL_NAME}-{int(time.time())}\"\n",
    "\n",
    "config = {\n",
    "    \"dataset\": DATASET_NAME,\n",
    "    \"split\": SPLIT,\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"max_new_tokens\": MAX_NEW_TOKENS,\n",
    "    \"batch_num\": BATCH_NUM,\n",
    "    \"pipeline\": \"Aristotle_baseline\",\n",
    "}\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"TRACE_LogicNLI\",  # 你可以换成自己的项目名\n",
    "    name=RUN_NAME,\n",
    "    config=config,\n",
    "    reinit=True,\n",
    ")\n",
    "\n",
    "print(\"wandb run url:\", run.get_url())\n",
    "\n",
    "### 在你原来的 Cell 3（实验配置 & wandb init） 末尾，加上几行：\n",
    "## 全局日志缓存（把每一步 stdout/stderr 收集到这里）\n",
    "LOG_BUFFERS = []\n",
    "\n",
    "## 准备 logs 目录 & 日志文件名（数据集 + split + 模型 + 时间戳）\n",
    "# os.makedirs(\"logs\", exist_ok=True)\n",
    "# LOG_FILENAME = f\"logs/{DATASET_NAME}_{SPLIT}_{MODEL_NAME}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "os.makedirs(\"experiments/logs\", exist_ok=True)\n",
    "LOG_FILENAME = f\"experiments/logs/{DATASET_NAME}_{SPLIT}_{MODEL_NAME}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "\n",
    "print(\"Log will be saved to:\", LOG_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac591214-197b-4cef-9795-bc4b23665d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4：封装一个运行命令的小工具（方便打印 & 报错）(Version 4)\n",
    "import subprocess\n",
    "import sys\n",
    "import textwrap\n",
    "\n",
    "def run_cmd(cmd: str, tag: str = \"\"):\n",
    "    global LOG_FILENAME\n",
    "\n",
    "    header = f\"[{tag}] \" if tag else \"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\">>> {header}Running command:\")\n",
    "    print(textwrap.indent(cmd, prefix=\"    \"))\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    # ⭐ 不再 capture_output，而是边读边写\n",
    "    process = subprocess.Popen(\n",
    "        cmd,\n",
    "        shell=True,\n",
    "        cwd=PROJECT_DIR,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        bufsize=1,   # 行缓冲，支持 tqdm 刷新\n",
    "    )\n",
    "\n",
    "    # 边跑边打印到 notebook，同时写入日志文件\n",
    "    with open(LOG_FILENAME, \"a\") as f:\n",
    "        for line in process.stdout:\n",
    "            sys.stdout.write(line)\n",
    "            sys.stdout.flush()\n",
    "            f.write(line)\n",
    "\n",
    "    process.wait()\n",
    "\n",
    "    if process.returncode != 0:\n",
    "        raise RuntimeError(f\"Command failed: {cmd}\")\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "437c4a15-03ec-450f-aa75-adb6f5f09a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4：封装一个运行命令的小工具（只显示进度条）(Version 5)\n",
    "import subprocess\n",
    "import sys\n",
    "import re\n",
    "\n",
    "def run_cmd(cmd: str, tag: str = \"\"):\n",
    "    global LOG_FILENAME\n",
    "\n",
    "    print(f\"\\n>>> Running [{tag}] ...\\n\")\n",
    "\n",
    "    # 启动子进程\n",
    "    process = subprocess.Popen(\n",
    "        cmd,\n",
    "        shell=True,\n",
    "        cwd=PROJECT_DIR,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        bufsize=1,   # 可让 tqdm 刷新\n",
    "    )\n",
    "\n",
    "    tqdm_pattern = re.compile(r\"\\d+%|\\|\\s*[\\d/]+|\\sit/s|\\sETA\")\n",
    "\n",
    "    with open(LOG_FILENAME, \"a\") as f:\n",
    "        for line in process.stdout:\n",
    "\n",
    "            # 1) 写入日志文件（完整内容）\n",
    "            f.write(line)\n",
    "\n",
    "            # 2) Jupyter 只显示 tqdm 相关输出\n",
    "            if tqdm_pattern.search(line):\n",
    "                sys.stdout.write(line)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "    process.wait()\n",
    "\n",
    "    if process.returncode != 0:\n",
    "        raise RuntimeError(f\"Command failed: {cmd}\")\n",
    "\n",
    "    print(f\"\\n>>> [{tag}] Done.\\n\")\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52ffc00-0948-48db-abd3-324599d106fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Running [TRANSLATE_DECOMPOSE] ...\n",
      "\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]Translation response:  To translate the given context and conjecture into logical form, we will follow the steps outlined in the task description. Let's begin:\n",
      "  0%|          | 1/300 [00:31<2:37:53, 31.68s/it]Translation response:  To translate the given context and conjecture into logical form, we will follow the steps outlined in the task description.\n",
      "  1%|          | 2/300 [01:01<2:32:39, 30.74s/it]Translation response:  To translate the given context and conjecture into logical form, we will follow the steps outlined in the task description.\n",
      "  1%|          | 3/300 [01:31<2:30:49, 30.47s/it]Translation response:  To translate the given context and conjecture into logical form, we will follow the steps outlined in the task description. Let's begin:\n"
     ]
    }
   ],
   "source": [
    "# Cell 5：Step A – translate_decompose（LogicNLI-dev）\n",
    "cmd_translate = f\"\"\"\n",
    "python translate_decompose.py \\\n",
    "  --api_key \"$OPENAI_API_KEY\" \\\n",
    "  --model_name \"{MODEL_NAME}\" \\\n",
    "  --data_path \"./data\" \\\n",
    "  --dataset_name \"{DATASET_NAME}\" \\\n",
    "  --split {SPLIT} \\\n",
    "  --max_new_tokens {MAX_NEW_TOKENS} \\\n",
    "  --batch_num {BATCH_NUM}\n",
    "\"\"\"\n",
    "\n",
    "run_cmd(cmd_translate, tag=\"TRANSLATE_DECOMPOSE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23a14ab7-b41b-4f10-aec9-67800353f8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      ">>> [NEGATE] Running command:\n",
      "\n",
      "    python negate.py   --dataset_name \"LogicNLI\"   --model \"gpt-4o\"\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6：Step B – negate（生成 negated_data）\n",
    "cmd_negate = f\"\"\"\n",
    "python negate.py \\\n",
    "  --dataset_name \"{DATASET_NAME}\" \\\n",
    "  --model \"{MODEL_NAME}\"\n",
    "\"\"\"\n",
    "\n",
    "start_time = time.time()\n",
    "### out_negate = run_cmd(cmd_negate)\n",
    "out_negate = run_cmd(cmd_negate, tag=\"NEGATE\")\n",
    "wandb.log({\"time_negate_sec\": time.time() - start_time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d9b6aa4-c76f-43dc-83e4-3c5eddc6ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7：Step C1 – search_resolve（no negation）\n",
    "cmd_search_no_neg = f\"\"\"\n",
    "python search_resolve.py \\\n",
    "  --api_key \"$OPENAI_API_KEY\" \\\n",
    "  --model_name \"{MODEL_NAME}\" \\\n",
    "  --data_path \"./data\" \\\n",
    "  --dataset_name \"{DATASET_NAME}\" \\\n",
    "  --split {SPLIT} \\\n",
    "  --negation False \\\n",
    "  --max_new_tokens {MAX_NEW_TOKENS} \\\n",
    "  --batch_num {BATCH_NUM}\n",
    "\"\"\"\n",
    "\n",
    "start_time = time.time()\n",
    "### out_search_no_neg = run_cmd(cmd_search_no_neg)\n",
    "out_search_no_neg = run_cmd(cmd_search_no_neg, tag=\"SEARCH_RESOLVE_NO_NEG\")\n",
    "wandb.log({\"time_search_no_neg_sec\": time.time() - start_time})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d291e077-e1fe-4659-8d0b-2340dbe9bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8：Step C2 – search_resolve（with negation）\n",
    "cmd_search_neg = f\"\"\"\n",
    "python search_resolve.py \\\n",
    "  --api_key \"$OPENAI_API_KEY\" \\\n",
    "  --model_name \"{MODEL_NAME}\" \\\n",
    "  --data_path \"./data\" \\\n",
    "  --dataset_name \"{DATASET_NAME}\" \\\n",
    "  --split {SPLIT} \\\n",
    "  --negation True \\\n",
    "  --max_new_tokens {MAX_NEW_TOKENS} \\\n",
    "  --batch_num {BATCH_NUM}\n",
    "\"\"\"\n",
    "\n",
    "start_time = time.time()\n",
    "### out_search_neg = run_cmd(cmd_search_neg)\n",
    "out_search_neg = run_cmd(cmd_search_neg, tag=\"SEARCH_RESOLVE_NEG\")\n",
    "wandb.log({\"time_search_neg_sec\": time.time() - start_time})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d001d7-c44e-42f3-83c6-fa484bc0cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9：Step D – evaluate + 解析 accuracy + 记录到 wandb\n",
    "import re\n",
    "\n",
    "cmd_eval = f\"\"\"\n",
    "python evaluate.py \\\n",
    "  --dataset_name \"{DATASET_NAME}\" \\\n",
    "  --model \"{MODEL_NAME}\"\n",
    "\"\"\"\n",
    "\n",
    "start_time = time.time()\n",
    "### out_eval = run_cmd(cmd_eval)\n",
    "out_eval = run_cmd(cmd_eval, tag=\"EVALUATE\")\n",
    "elapsed_eval = time.time() - start_time\n",
    "wandb.log({\"time_evaluate_sec\": elapsed_eval})\n",
    "\n",
    "# 从 stdout 中解析 Accuracy\n",
    "match = re.search(r\"Accuracy:\\s*([0-9.]+)\", out_eval)\n",
    "if match:\n",
    "    acc = float(match.group(1))\n",
    "    print(f\"\\nParsed Accuracy = {acc:.4f}\")\n",
    "    wandb.log({\"dev_accuracy\": acc})\n",
    "else:\n",
    "    print(\"\\n⚠ 没能从 evaluate 输出中解析出 Accuracy，请检查 evaluate.py 的打印格式。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6228d94b-d69d-4b6c-97ae-07a3e4909622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10：收尾（wandb.finish）(version 3)\n",
    "# 可选：把 log 文件同步到 wandb\n",
    "try:\n",
    "    wandb.save(LOG_FILENAME)\n",
    "    print(\"Log file also saved to wandb.\")\n",
    "except Exception as e:\n",
    "    print(\"wandb.save failed:\", e)\n",
    "\n",
    "wandb.finish()\n",
    "print(\"Done. Run URL:\", run.get_url())\n",
    "print(\"Final log file:\", LOG_FILENAME)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
